{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM5vHnKRcfTAGx9XmlBqyEa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jonofficial/Resources/blob/main/Docker-notes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ORpS-XVqynH"
      },
      "outputs": [],
      "source": [
        "# WHAT IS DOCKER?\n",
        "# A platform for building, running and shipping applications\n",
        "# you may encounter cases when an application that one has developed runs on one machine but not on others\n",
        "# this might be due to reasons like:\n",
        "# one or more files missing\n",
        "# software version mismatch (target machine may run diff version)\n",
        "# different configuration settings\n",
        "\n",
        "# docker enables:\n",
        "# 1. consistency across environments (ensures an application runs the same on any OS and any machine)\n",
        "# 2. Isolation (isolates our app from the dependencies, so no more clashes between applications)\n",
        "# 3. Portability (easily moves app from testing to development to other processess)\n",
        "# 4. version control (helps us track our app, can return to previous version when anything goes wrong)\n",
        "# 5. scalability (easily creates copy of our application when needed)\n",
        "# 6. DevOps integration\n",
        "\n",
        "# HOW DOES DOCKER WORK?\n",
        "# mainly depends on 2 concepts: images and containers\n",
        "# An image is a lightweight, standalone, executable package that includes everything to run a piece of software including the code, runtime, OS,libraries, system-tools\n",
        "# A container is a runnable instance of a docker image\n",
        "# we can run multiple containers from a single image\n",
        "# analogically docker image is the recipe and container is the cake that u cook from recipe.\n",
        "# container - an isolated environment for running an application\n",
        "# virtual machine - an abstraction of a machine (physical hardware)\n",
        "\n",
        "# DOCKER VOLUME\n",
        "# A docker volume is a persistent data storage mechanism that allows data to be shared between a dock container and a host machine\n",
        "# volume ensures data durability and persistence even if the container is stopped or removed\n",
        "# think of it as a shared folder or storage container compartment of container\n",
        "\n",
        "# DOCKER NETWORK\n",
        "# a communication channel to enable containers to talk to each other or with external world (enables container to share info and services while maintaining isolation)\n",
        "\n",
        "# DOCKER WORKFLOW (divided into 3 parts)\n",
        "# 1. Docker client (CLI or GUI) - where user gives command\n",
        "# 2. Docker Host (Docker Daemon) - runs the container\n",
        "# 3. Docker registry (Docker Hub) - docker images are stored\n",
        "\n",
        "# you can checkout docker hub in google for public images\n",
        "# if we wanna create an image of our own, then we do it by docker file\n",
        "\n",
        "# to create an public image\n",
        "docker pull ubuntu\n",
        "\n",
        "# to create and run a container from image\n",
        "docker run -it ubuntu\n",
        "# close terminal to quite\n",
        "\n",
        "# to create our own image\n",
        "# first create a folder (docker-course), inside the course create another folder hello-docker\n",
        "# create two files inside hello-docker:\n",
        "Dockerfile\n",
        "hello.js\n",
        "\n",
        "# inside Dockerfile type the below commands\n",
        "FROM node:20-alpine\n",
        "\n",
        "WORKDIR /app\n",
        "\n",
        "COPY . .\n",
        "\n",
        "CMD node hello.js\n",
        "\n",
        "# open terminal\n",
        "cd hello-docker\n",
        "docker build -t hello-docker .\n",
        "\n",
        "# to check whether the image is created\n",
        "docker images\n",
        "\n",
        "# to build container from the created image\n",
        "docker run hello-docker\n",
        "\n",
        "# to run the container\n",
        "docker run -it hello-docker sh\n",
        "node hello.js\n",
        "\n",
        "# download docker-desktop for GUI, u can see containers and images in the desktop app\n",
        "\n",
        "# to do some complex testing, create a react vite project (the objective here is that instead of installing all the node modules with \"npm i\", we are dockerising the project to ship all the required modules)\n",
        "npm create vite@latest react-docker\n",
        "# select react+TS\n",
        "cd react-docker\n",
        "# create a Dockerfile inside react-docker folder\n",
        "\n",
        "# INSIDE DOCKERFILE\n",
        "\n",
        "# set the base image to create the image for react app\n",
        "FROM node:20-alpine\n",
        "\n",
        "# create a user with permissions to run the app\n",
        "# -S -> create a system user\n",
        "# -G -> add the user to a group\n",
        "# This is done to avoid running the app as root\n",
        "# If the app is run as root, any vulnerability in the app can be exploited to gain access to the host system\n",
        "# It's a good practice to run the app as a non-root user\n",
        "RUN addgroup app && adduser -S -G app app\n",
        "\n",
        "# set the user to run the app\n",
        "USER app\n",
        "\n",
        "# set the working directory to /app\n",
        "WORKDIR /app\n",
        "\n",
        "# copy package.json and package-lock.json to the working directory\n",
        "# This is done before copying the rest of the files to take advantage of Docker’s cache\n",
        "# If the package.json and package-lock.json files haven’t changed, Docker will use the cached dependencies\n",
        "COPY package*.json ./\n",
        "\n",
        "# sometimes the ownership of the files in the working directory is changed to root\n",
        "# and thus the app can't access the files and throws an error -> EACCES: permission denied\n",
        "# to avoid this, change the ownership of the files to the root user\n",
        "USER root\n",
        "\n",
        "# change the ownership of the /app directory to the app user\n",
        "# chown -R <user>:<group> <directory>\n",
        "# chown command changes the user and/or group ownership of for given file.\n",
        "RUN chown -R app:app .\n",
        "\n",
        "# change the user back to the app user\n",
        "USER app\n",
        "\n",
        "# install dependencies\n",
        "RUN npm install\n",
        "\n",
        "# copy the rest of the files to the working directory\n",
        "COPY . .\n",
        "\n",
        "# expose port 5173 to tell Docker that the container listens on the specified network ports at runtime\n",
        "EXPOSE 5173\n",
        "\n",
        "# command to run the app\n",
        "CMD npm run dev\n",
        "\n",
        "# END OF DOCKER FILE\n",
        "\n",
        "# create a new file inside react-docker\n",
        ".dockerignore\n",
        "\n",
        "# to build an image\n",
        "docker build -t react-docker .\n",
        "\n",
        "# to use the image, we have to run it\n",
        "docker run react-docker\n",
        "\n",
        "# but when we go to localhost: 5173, the site isnt running because we have to map the port of container to port of docker (even if we commanded docker to listen to port 5173 using EXPOSE in Dockerfile)\n",
        "# to expose host navigate to package.json\n",
        "dev: \"vite --host\"; # make the changes add \"--host\"\n",
        "\n",
        "# go to terminal and type the command\n",
        "docker run -p 5173:5173 react-docker # if it doesnt run, then clear the running containers and other useless containers using below\n",
        "\n",
        "# to see container ID's and their images\n",
        "docker ps # only shows active/running containers\n",
        "\n",
        "# to all containers\n",
        "docker ps -a\n",
        "\n",
        "# to stop a running container\n",
        "docker stop docker-name # either u can use the container name or its ID (first 3 letters of its ID is enough)\n",
        "\n",
        "# to remove all inactive containers\n",
        "docker container prune\n",
        "\n",
        "# to remove specific container\n",
        "docker rm docker-name/ID\n",
        "\n",
        "# to remove a runnning container use the above container with --force\n",
        "docker run docker-name --force\n",
        "\n",
        "# after containerising the project, when we make changes in the code base, the container doesnt get updated. so to keep the container updated\n",
        "docker run -p 5173:5173 -v \"$(pwd):/app\" -v /app/node_modules react-docker\n",
        "\n",
        "# PUBLISHING A DOCKER IMAGE\n",
        "cd react-docker\n",
        "docker login # if already logged in docker-desktop then it should automatically authenticate you\n",
        "\n",
        "# to publish\n",
        "docker tag react-docker username/react-docker # username can be found from docker-desktop\n",
        "docker push username/react-docker\n",
        "\n",
        "# DOCKER COMPOSE\n",
        "# running all these commands to build an image, a container out of the image and running the container and mapping them to host - is tedious\n",
        "# we can automate all these using docker compose using one straight-forward command\n",
        "# it uses a yaml file to configure the services,networks,volumes for your application\n",
        "# we dont have to run 10 commands for 10 containers for your application\n",
        "# we can put all the info in a single file and a single command to run the file\n",
        "# the file can be put manually or docker provides a CLI called docker-init to generate these files for us\n",
        "# with docker-init we initialize our app with all the needed files needed to dockerize it by specifying tech choices\n",
        "\n",
        "# create a new vite project\n",
        "cd vite-project\n",
        "docker init\n",
        "\n",
        "# it asks some few questions about tech choices, select appropriately and it automatically creates new files for us\n",
        "Dockerfile\n",
        ".dockerignore\n",
        "compose.yaml\n",
        "\n",
        "# go to compose.yaml and change server to web, remove environmental variables if not used\n",
        "# add volumes to the yaml file\n",
        "\n",
        "services:\n",
        "  web:\n",
        "    build:\n",
        "      context: .\n",
        "    ports:\n",
        "      - 5173:5173\n",
        "    volumes:\n",
        "      - .:/app\n",
        "      - /app/node_modules\n",
        "\n",
        "# now run\n",
        "docker compose up\n",
        "\n",
        "# DOCKER COMPOSE WATCH  (new feature of docker) - most optimal for developers today\n",
        "# but eventhough docker compose helps us make the code base upto date, it still makes us create new containers to run when package files are changed (it automatically stops old containers when new ones are created)\n",
        "# to solve the problem we have docker compose watch\n",
        "# 3 things can be done using this - sync, rebuild, sync-restart\n",
        "\n",
        "# DOCKER SCOUT (new feature)\n",
        "# when we are creating images for our application, we are essentially stacking layers of existing images\n",
        "# but some of the images may have security vulnerabilities making our application prone to attacks\n",
        "# docker scout is a tool that helps us be proactive about our security - scans all the images and creates a detailed list called SBOM (software bill of materials)\n",
        "# then docker scout checks the list against the always updated databases of known vulnerabilities. if it finds any , it lets us know\n",
        "\n",
        "view packages and CVE's button - complete report analysis of our image"
      ]
    }
  ]
}